name: Upload GGUF Model to HuggingFace Hub
description: Uploads a GGUF format model to HuggingFace Hub repository. Supports both creating new repositories and updating existing ones.

inputs:
  - {name: gguf_model, type: Model, description: 'Path to GGUF model directory from Convert to GGUF component'}
  - {name: repo_id, type: String, description: 'HuggingFace repository ID (e.g., username/model-name)'}
  - {name: hf_token, type: String, description: 'HuggingFace access token with write permissions'}
  - {name: private, type: String, description: 'Whether to make repository private (true/false)'}
  - {name: commit_message, type: String, description: 'Commit message for the upload'}

outputs:
  - {name: repository_url, type: String}

metadata:
  annotations:
    author: Upload GGUF to HuggingFace Component

implementation:
  container:
    image: python:3.10
    command:
      - sh
      - -c
      - (pip install --no-cache-dir huggingface_hub > /dev/null 2>&1) && "$0" "$@"
      - python3
      - -u
      - -c
      - |
        def _make_parent_dirs_and_return_path(file_path):
            import os
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            return file_path
        
        def upload_gguf_to_hf(
            gguf_model_path,
            repo_id,
            hf_token,
            private,
            commit_message,
            repository_url_path,
        ):
            import os
            import json
            import logging
            from huggingface_hub import HfApi, login, create_repo
            
            logging.basicConfig(level=logging.INFO)
            logger = logging.getLogger("gguf_uploader")
            
            logger.info("=" * 70)
            logger.info("Starting GGUF Model Upload to HuggingFace Hub")
            logger.info("=" * 70)
            logger.info(f"GGUF model directory: {gguf_model_path}")
            logger.info(f"Target repository: {repo_id}")
            logger.info(f"Private repository: {private}")
            
            def get_token_value(token_arg):
                if not token_arg:
                    raise ValueError("HuggingFace token is required")
                token_str = str(token_arg).strip()
                if os.path.exists(token_str):
                    try:
                        with open(token_str) as f:
                            content = f.read().strip()
                            return content if content else None
                    except Exception as e:
                        logger.error(f"Failed to read token file: {e}")
                        raise
                else:
                    return token_str if token_str and token_str != "None" else None
            
            # Get and validate token
            token = get_token_value(hf_token)
            if not token:
                raise ValueError("Valid HuggingFace token is required")
            
            # Parse private flag
            is_private = private.lower() in ['true', '1', 'yes']
            
            # Login to HuggingFace
            logger.info("Logging in to HuggingFace Hub...")
            try:
                login(token=token)
                logger.info("Successfully logged in to HuggingFace Hub")
            except Exception as e:
                logger.error(f"Failed to login to HuggingFace: {e}")
                raise
            
            # Initialize HF API
            api = HfApi()
            
            # Verify GGUF model directory exists
            if not os.path.exists(gguf_model_path):
                raise FileNotFoundError(f"GGUF model directory not found: {gguf_model_path}")
            
            # Find GGUF files and metadata
            gguf_files = []
            metadata_file = None
            
            for item in os.listdir(gguf_model_path):
                item_path = os.path.join(gguf_model_path, item)
                if item.endswith('.gguf'):
                    gguf_files.append((item, item_path))
                    logger.info(f"Found GGUF file: {item}")
                elif item == 'conversion_metadata.json':
                    metadata_file = item_path
                    logger.info(f"Found metadata file: {item}")
            
            if not gguf_files:
                raise FileNotFoundError(f"No GGUF files found in {gguf_model_path}")
            
            logger.info(f"Total GGUF files to upload: {len(gguf_files)}")
            
            # Create repository if it doesn't exist
            logger.info(f"Creating/verifying repository: {repo_id}")
            try:
                create_repo(
                    repo_id=repo_id,
                    token=token,
                    private=is_private,
                    exist_ok=True,
                    repo_type="model"
                )
                logger.info(f"Repository ready: {repo_id}")
            except Exception as e:
                logger.error(f"Failed to create/verify repository: {e}")
                raise
            
            # Upload GGUF files
            logger.info("=" * 70)
            logger.info("Uploading GGUF files...")
            logger.info("=" * 70)
            
            uploaded_files = []
            for filename, filepath in gguf_files:
                try:
                    file_size_mb = os.path.getsize(filepath) / (1024 * 1024)
                    logger.info(f"Uploading {filename} ({file_size_mb:.2f} MB)...")
                    
                    api.upload_file(
                        path_or_fileobj=filepath,
                        path_in_repo=filename,
                        repo_id=repo_id,
                        repo_type="model",
                        token=token,
                        commit_message=commit_message
                    )
                    
                    logger.info(f"✓ Successfully uploaded: {filename}")
                    uploaded_files.append(filename)
                    
                except Exception as e:
                    logger.error(f"✗ Failed to upload {filename}: {e}")
                    raise
            
            # Upload metadata if available
            if metadata_file:
                try:
                    logger.info("Uploading conversion metadata...")
                    api.upload_file(
                        path_or_fileobj=metadata_file,
                        path_in_repo="conversion_metadata.json",
                        repo_id=repo_id,
                        repo_type="model",
                        token=token,
                        commit_message="Upload conversion metadata"
                    )
                    logger.info("✓ Metadata uploaded successfully")
                except Exception as e:
                    logger.warning(f"Failed to upload metadata (non-critical): {e}")
            

            
            # Generate repository URL
            repo_url = f"https://huggingface.co/{repo_id}"
            
            logger.info("=" * 70)
            logger.info("Upload Complete!")
            logger.info("=" * 70)
            logger.info(f"Repository URL: {repo_url}")
            logger.info(f"Uploaded files: {', '.join(uploaded_files)}")
            logger.info(f"Private: {is_private}")
            logger.info("=" * 70)
            logger.info("Your GGUF model is now available on HuggingFace Hub!")
            logger.info("=" * 70)
            
            # Write repository URL to output
            os.makedirs(os.path.dirname(repository_url_path), exist_ok=True)
            with open(repository_url_path, 'w') as f:
                f.write(repo_url)
            
            logger.info(f"Repository URL saved to: {repository_url_path}")
        
        import argparse
        _parser = argparse.ArgumentParser(prog="Upload GGUF Model to HuggingFace Hub", description="Uploads GGUF model to HuggingFace Hub")
        _parser.add_argument("--gguf_model", dest="gguf_model_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--repo_id", dest="repo_id", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--hf_token", dest="hf_token", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--private", dest="private", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--commit_message", dest="commit_message", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--repository_url", dest="repository_url_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())
        upload_gguf_to_hf(**_parsed_args)

    args:
      - --gguf_model
      - {inputPath: gguf_model}
      - --repo_id
      - {inputValue: repo_id}
      - --hf_token
      - {inputValue: hf_token}
      - --private
      - {inputValue: private}
      - --commit_message
      - {inputValue: commit_message}
      - --repository_url
      - {outputPath: repository_url}
